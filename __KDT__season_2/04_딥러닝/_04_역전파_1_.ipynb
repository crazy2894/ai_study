{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 역전파 (Back Propagation)\n",
    "\n",
    "- 순 전파 : 입력 층으로부터 출력층까지의 데이터의 이동\n",
    "- 역 전파 : 출력 층으로부터 입력 층 까지의 오류(비용)함수 에 대하여 계산하고, 가중치가 이 함수에 미치는 영향을 계산하고, 이를 최소화 하는 방향으로 업데이트 한다.\n",
    "\n",
    "## 경사 하강법의 역전파\n",
    "\n",
    "- 함수의 기울기(미분 : Gradient)를 사용하여 함수의 최솟값을 찾는 방법\n",
    "    - 딥 러닝 에서의 최솟값은 비용함수(정답과의 거리의 함수) 를 최소화 하는 방향\n",
    "- 함수의 기울기 : 함수의 증가율을 보여줌\n",
    "- 오류가 역으로 전파하여 파라미터를 업데이트 한다.\n",
    "\n",
    "## 역전파 과정\n",
    "\n",
    "순전파 → 손실계산 → 오류 역전파 → 가중치 업데이트 (경사 하강법 or 옵티마이저)\n",
    "\n",
    "## 역전파의 장점\n",
    "\n",
    "- 속도의 향상\n",
    "- 심층 학습 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 체인 룰\n",
    "\n",
    "- 합성 함수:\n",
    "    \n",
    "    $$\n",
    "    z = g(x) \\\\\n",
    "    y = f(z) \\\\ \\space \\\\ \\text{and} \\\\ \\space \\\\\n",
    "    y = f(g(x))\n",
    "    $$\n",
    "    \n",
    "- 체인 룰:\n",
    "    \n",
    "    $$\n",
    "    \\frac{\\partial y}{\\partial x} = \n",
    "    \n",
    "    \\frac{\\partial y}{\\partial g(x)} \\frac{\\partial g(x)}{\\partial x}\n",
    "    \n",
    "     = \\frac{\\partial y}{\\partial z} \\frac{\\partial z}{\\partial x}\n",
    "    $$\n",
    "    \n",
    "    에서 $w$ 에 대한 $E$ 의 변화량으로 표현하면\n",
    "    \n",
    "    $$\n",
    "    \\frac{\\partial E}{\\partial w} = \n",
    "    \\frac{\\partial z_{out}}{\\partial w}\n",
    "    \\frac{\\partial \\hat{y}_i}{\\partial z_{out}}\n",
    "    \\frac{\\partial E}{\\partial \\hat{y}}\n",
    "    $$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
