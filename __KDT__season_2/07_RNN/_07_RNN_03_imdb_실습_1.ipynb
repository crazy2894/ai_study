{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "보류\n",
        "```py\n",
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.xlabel('epoch')\n",
        "# plt.ylabel('loss')\n",
        "# plt.legend(['train', 'val'])\n",
        "# plt.show()\n",
        "# test_loss, test_acc = model.evaluate(x_test,y_test_one_hot)\n",
        "# print('test_acc:', test_acc)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0Ngk71X1j2E",
        "outputId": "f3c57ac8-a7c0-499b-f634-c47b587a0f54"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "176/176 [==============================] - 23s 122ms/step - loss: 0.5100 - accuracy: 0.7471 - val_loss: 0.3963 - val_accuracy: 0.8204\n",
            "Epoch 2/5\n",
            "176/176 [==============================] - 22s 127ms/step - loss: 0.3154 - accuracy: 0.8714 - val_loss: 0.3502 - val_accuracy: 0.8460\n",
            "Epoch 3/5\n",
            "176/176 [==============================] - 22s 127ms/step - loss: 0.2411 - accuracy: 0.9090 - val_loss: 0.4351 - val_accuracy: 0.8388\n",
            "Epoch 4/5\n",
            "176/176 [==============================] - 21s 121ms/step - loss: 0.1792 - accuracy: 0.9339 - val_loss: 0.4065 - val_accuracy: 0.8412\n",
            "782/782 [==============================] - 13s 16ms/step\n",
            "Epoch 1/5\n",
            "176/176 [==============================] - 24s 133ms/step - loss: 0.6087 - accuracy: 0.6528 - val_loss: 0.4966 - val_accuracy: 0.7736\n",
            "Epoch 2/5\n",
            "176/176 [==============================] - 22s 124ms/step - loss: 0.3586 - accuracy: 0.8530 - val_loss: 0.3938 - val_accuracy: 0.8244\n",
            "Epoch 3/5\n",
            "176/176 [==============================] - 21s 122ms/step - loss: 0.2440 - accuracy: 0.9055 - val_loss: 0.3591 - val_accuracy: 0.8428\n",
            "Epoch 4/5\n",
            "176/176 [==============================] - 23s 131ms/step - loss: 0.1658 - accuracy: 0.9407 - val_loss: 0.3964 - val_accuracy: 0.8472\n",
            "Epoch 5/5\n",
            "176/176 [==============================] - 22s 124ms/step - loss: 0.0977 - accuracy: 0.9674 - val_loss: 0.4759 - val_accuracy: 0.8160\n",
            "782/782 [==============================] - 13s 17ms/step\n",
            "Epoch 1/5\n",
            "176/176 [==============================] - 81s 456ms/step - loss: 0.6583 - accuracy: 0.6000 - val_loss: 0.5225 - val_accuracy: 0.7404\n",
            "Epoch 2/5\n",
            "176/176 [==============================] - 83s 472ms/step - loss: 0.3980 - accuracy: 0.8308 - val_loss: 0.3486 - val_accuracy: 0.8568\n",
            "Epoch 3/5\n",
            "176/176 [==============================] - 82s 468ms/step - loss: 0.2708 - accuracy: 0.8926 - val_loss: 0.3607 - val_accuracy: 0.8552\n",
            "Epoch 4/5\n",
            "176/176 [==============================] - 80s 452ms/step - loss: 0.1850 - accuracy: 0.9321 - val_loss: 0.3321 - val_accuracy: 0.8612\n",
            "Epoch 5/5\n",
            "176/176 [==============================] - 81s 463ms/step - loss: 0.1148 - accuracy: 0.9600 - val_loss: 0.3665 - val_accuracy: 0.8684\n",
            "782/782 [==============================] - 42s 53ms/step\n",
            "Epoch 1/5\n",
            "176/176 [==============================] - 84s 470ms/step - loss: 0.5577 - accuracy: 0.7104 - val_loss: 0.4093 - val_accuracy: 0.8288\n",
            "Epoch 2/5\n",
            "176/176 [==============================] - 79s 447ms/step - loss: 0.3328 - accuracy: 0.8665 - val_loss: 0.4018 - val_accuracy: 0.8260\n",
            "Epoch 3/5\n",
            "176/176 [==============================] - 81s 458ms/step - loss: 0.2353 - accuracy: 0.9128 - val_loss: 0.3674 - val_accuracy: 0.8404\n",
            "Epoch 4/5\n",
            "176/176 [==============================] - 82s 465ms/step - loss: 0.1684 - accuracy: 0.9395 - val_loss: 0.3157 - val_accuracy: 0.8872\n",
            "Epoch 5/5\n",
            "176/176 [==============================] - 82s 467ms/step - loss: 0.1080 - accuracy: 0.9628 - val_loss: 0.3418 - val_accuracy: 0.8844\n",
            "782/782 [==============================] - 56s 68ms/step\n"
          ]
        }
      ],
      "source": [
        "accuracys = {}\n",
        "for doc_size in [100, 400]:\n",
        "    for max_feature in [10000, 20000]:\n",
        "        max_features = max_feature\n",
        "        (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "        \n",
        "        max_len = doc_size\n",
        "        x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
        "        x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
        "        y_train_one_hot = to_categorical(y_train)\n",
        "        y_test_one_hot = to_categorical(y_test)\n",
        "\n",
        "        early_stopping = EarlyStopping(patience = 2)\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Embedding(max_features, 64, input_length=max_len))\n",
        "        model.add(layers.SimpleRNN(32, activation='tanh', return_sequences=False))\n",
        "        model.add(layers.Dense(16, activation='tanh'))\n",
        "        model.add(layers.Dense(2, activation = 'softmax'))\n",
        "\n",
        "        model.compile(optimizer=RMSprop(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        history=model.fit(x_train, y_train_one_hot, epochs=5,\n",
        "                          batch_size=128, validation_split=0.1,\n",
        "                          callbacks = [early_stopping])\n",
        "\n",
        "        preds = model.predict(x_test)\n",
        "        labels=[0,1]\n",
        "        preds1 = [labels[np.argmax(probs)] for probs in preds]\n",
        "        accuracys[f\"{max_len},{max_feature}\"] = (accuracy_score(y_test, preds1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "문장 길이, 코퍼스: 100,10000, 정확도 : 0.84144\n",
            "문장 길이, 코퍼스: 100,20000, 정확도 : 0.81892\n",
            "문장 길이, 코퍼스: 400,10000, 정확도 : 0.86112\n",
            "문장 길이, 코퍼스: 400,20000, 정확도 : 0.86636\n"
          ]
        }
      ],
      "source": [
        "accuracys\n",
        "\n",
        "for key, accu in zip(accuracys, accuracys.values()):\n",
        "    print(f\"문장 길이, 코퍼스: {key}, 정확도 : {accu}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
